{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from dlai_grader.grading import test_case, print_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e87877",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feedback(test_cases):\n",
    "    num_cases = len(test_cases)\n",
    "    failed_cases = [t for t in test_cases if t.failed == True]\n",
    "    feedback_msg = \"\\033[92m All tests passed!\"\n",
    "    if failed_cases:\n",
    "        feedback_msg = \"\"\n",
    "        for failed_case in failed_cases:\n",
    "            feedback_msg += f\"\\033[91mFailed test case: {failed_case.msg}.\\nExpected: {failed_case.want}\\nGot: {failed_case.got}\\n\\n\"\n",
    "    print(feedback_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11724d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scaled_dot_product_attention(target):\n",
    "    \n",
    "    def g():\n",
    "        q = np.array([[1, 1, 0, 1], [0, 1, 1, 1], [1, 0, 1, 1]]).astype(np.float32)\n",
    "        k = np.array([[1, 1, 0, 1], [1, 0, 1, 1 ], [1, 1, 1, 0], [0, 0, 0, 1]]).astype(np.float32)\n",
    "        v = np.array([[0, 0], [1, 0], [1, 0], [1, 1]]).astype(np.float32)\n",
    "        mask = np.array([[[0, 1, 0, 1], [1, 0, 0, 1], [1, 1, 0, 1]]])\n",
    "\n",
    "        unmasked_weights_solution = [[0.3874556,  0.23500372, 0.23500372, 0.14253697],\n",
    "                                     [0.2772748,  0.2772748,  0.2772748,  0.16817565],\n",
    "                                     [0.23500372, 0.3874556,  0.23500372, 0.14253697]]\n",
    "        \n",
    "        unmasked_output_solution = [[0.6125444,  0.14253697],\n",
    "                                    [0.7227252,  0.16817565],\n",
    "                                    [0.7649963,  0.14253697]]\n",
    "        \n",
    "        \n",
    "        masked_weights_solution = [[0.0,        0.62245935, 0.0,        0.37754068],\n",
    "                                   [0.62245935, 0.0,        0.0,        0.37754068],\n",
    "                                   [0.30719587, 0.5064804,  0.0,        0.18632373]]\n",
    "        \n",
    "        \n",
    "        masked_output_solution = [[1.0,        0.37754068],\n",
    "                                  [0.37754068, 0.37754068],\n",
    "                                  [0.6928041,  0.18632373]]\n",
    "        \n",
    "        cases = []\n",
    "        \n",
    "        # Test for unmasked\n",
    "        attention, weights = target(q, k, v, None)\n",
    "\n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(weights):\n",
    "            t.failed = True\n",
    "            t.msg = \"Attention weights must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(weights)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "\n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(weights).numpy()) != (q.shape[0], k.shape[1]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of attention weights. Expected shape: ({q.shape[0]}, {k.shape[1]})\"\n",
    "            t.want = (q.shape[0], k.shape[1])\n",
    "            t.got = tuple(tf.shape(weights).numpy())\n",
    "        cases.append(t)        \n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(weights, unmasked_weights_solution):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong unmasked attention weights\"\n",
    "            t.want = unmasked_weights_solution\n",
    "            t.got = weights\n",
    "        cases.append(t) \n",
    "\n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(attention):\n",
    "            t.failed = True\n",
    "            t.msg = \"Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(attention)\n",
    "            cases.append(t)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "        \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(attention).numpy()) != (q.shape[0], v.shape[1]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of output. Expected shape: ({q.shape[0]}, {v.shape[1]})\"\n",
    "            t.want = (q.shape[0], v.shape[1])\n",
    "            t.got = tuple(tf.shape(attention).numpy())\n",
    "        cases.append(t)    \n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(attention, unmasked_output_solution):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong unmasked output.\"\n",
    "            t.want = unmasked_output_solution\n",
    "            t.got = attention\n",
    "        cases.append(t) \n",
    "        \n",
    "        # Test for masked\n",
    "        attention, weights = target(q, k, v, mask)\n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(weights, masked_weights_solution):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong masked attention weights\"\n",
    "            t.want = masked_weights_solution\n",
    "            t.got = weights\n",
    "        cases.append(t)         \n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(attention, masked_output_solution):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong masked output\"\n",
    "            t.want = masked_output_solution\n",
    "            t.got = attention\n",
    "        cases.append(t)\n",
    "        \n",
    "        return cases\n",
    "    \n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encoderlayer(target):\n",
    "    \n",
    "    def g():\n",
    "        tf.keras.utils.set_random_seed(SEED)\n",
    "        q = np.array([[[1, 0, 1, 1], [0, 1, 0, 1], [1, 1, 0, 1]]]).astype(np.float32)\n",
    "        encoder_layer1 = target(4, 2, 8)\n",
    "        \n",
    "        encoded_training_true = [[-0.6943532,  -1.1015786,   0.30987337,  1.4860584 ],\n",
    "                                 [ 0.11547165,  0.8349443,  -1.6664022,   0.71598625],\n",
    "                                 [ 0.37704456,  0.9044332,  -1.6940061,   0.4125284 ]]\n",
    "        \n",
    "        \n",
    "        encoded_training_false = [[-0.6943532,  -1.1015786,   0.30987337,  1.4860584, ],\n",
    "                                  [ 0.11547165,  0.8349443,  -1.6664022,   0.71598625,],\n",
    "                                  [ 0.40035784,  0.8880369,  -1.6980288,   0.40963417,]]\n",
    "        \n",
    "        encoded = encoder_layer1(q, True, np.array([[1, 0, 1]]))\n",
    "        \n",
    "        cases = []\n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(encoded):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(encoded)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "\n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(encoded).numpy()) != (1, q.shape[1], q.shape[2]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of output. Expected shape: (1, {q.shape[1]}, {q.shape[2]})\"\n",
    "            t.want = (1, q.shape[1], q.shape[2])\n",
    "            t.got = tuple(tf.shape(encoded).numpy())\n",
    "        cases.append(t)    \n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(encoded.numpy(), encoded_training_true):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values when training=True\"\n",
    "            t.want = encoded_training_true\n",
    "            t.got = encoded.numpy()\n",
    "        cases.append(t)            \n",
    "\n",
    "        encoded = encoder_layer1(q, True, np.array([[1, 0, 1]]))\n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(encoded.numpy(), encoded_training_false):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values when training=False\"\n",
    "            t.want = encoded_training_false\n",
    "            t.got = encoded.numpy()\n",
    "        cases.append(t)            \n",
    "        return cases\n",
    "\n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39744fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encoder(target):\n",
    "    def g():\n",
    "        tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "        embedding_dim=4\n",
    "\n",
    "        encoderq = target(num_layers=2,\n",
    "                          embedding_dim=embedding_dim,\n",
    "                          num_heads=2,\n",
    "                          fully_connected_dim=8,\n",
    "                          input_vocab_size=32,\n",
    "                          maximum_position_encoding=5)\n",
    "\n",
    "        x = np.array([[2, 1, 1], [0, 2, 1]])\n",
    "\n",
    "        encoderq_output = encoderq(x, True, None)\n",
    "\n",
    "        case_1_result = [[[-1.5521252e+00,  1.2275430e+00,  2.8751713e-01,  3.7065268e-02],\n",
    "                          [ 9.4034457e-01, -6.4952612e-01, -1.2968377e+00,  1.0060191e+00],\n",
    "                          [ 2.8042072e-01, -1.3738929e+00, -3.0059353e-01,  1.3940656e+00]],\n",
    "\n",
    "                         [[-1.7030637e+00,  8.6491209e-01,  4.0807986e-01,  4.3007189e-01],\n",
    "                          [-6.9350564e-01, -1.0131397e+00,  1.3350804e-01,  1.5731372e+00],\n",
    "                          [-3.7993553e-01, -1.1846002e+00, -1.4650300e-03,  1.5660008e+00]]]\n",
    "        \n",
    "        case_2_result = [[[-1.5422106,   1.1804703,   0.4660407,  -0.10430057],\n",
    "                          [-1.6235152,   1.051704,    0.5034224,   0.06838872],\n",
    "                          [-0.12116455, -1.3260406,  -0.04442041,  1.4916254 ]],\n",
    "\n",
    "                         [[-1.4519225,   1.3070422,   0.36660305, -0.22172265],\n",
    "                          [ 1.4702849,  -0.7520739,  -1.0713955,   0.35318464],\n",
    "                          [-1.4717183,  -0.0867067,   0.22596014,  1.3324649 ]]]\n",
    "        \n",
    "        case_3_result = [[[-1.6598201,   1.0180895,   0.28498387,  0.35674685],\n",
    "                          [-0.10208954, -1.0945475,  -0.42039752,  1.6170347 ],\n",
    "                          [-0.13384242, -1.2241358,  -0.20461643,  1.5625945 ]],\n",
    "\n",
    "                         [[-1.6484364,   1.0502913,   0.3171085,   0.28103673],\n",
    "                          [-0.74074364, -0.7831033,  -0.15376769,  1.6776146 ],\n",
    "                          [-0.2733949,  -1.1927879,  -0.11179274,  1.5779753 ]]]\n",
    "        \n",
    "        cases = []\n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(encoderq_output):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(encoderq_output)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "        \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(encoderq_output).numpy()) != (x.shape[0], x.shape[1], embedding_dim):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of output. Expected shape: ({x.shape[0]}, {x.shape[1]}, {embedding_dim})\"\n",
    "            t.want = ({x.shape[0]}, {x.shape[1]}, {embedding_dim})\n",
    "            t.got = tuple(tf.shape(encoderq_output).numpy())\n",
    "        cases.append(t)    \n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(encoderq_output.numpy(), case_1_result):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values for test case 1\"\n",
    "            t.want = case_1_result\n",
    "            t.got = encoderq_output.numpy()\n",
    "        cases.append(t)            \n",
    "\n",
    "        encoderq_output = encoderq(x, True, np.array([[[[1., 1., 1.]]], [[[1., 1., 0.]]]]))\n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(encoderq_output.numpy(), case_2_result):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values for test case 2\"\n",
    "            t.want = case_2_result\n",
    "            t.got = encoderq_output.numpy()\n",
    "        cases.append(t) \n",
    "        \n",
    "        encoderq_output = encoderq(x, False, np.array([[[[1., 1., 1.]]], [[[1., 1., 0.]]]]))\n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(encoderq_output.numpy(), case_3_result):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values for test case 3\"\n",
    "            t.want = case_3_result\n",
    "            t.got = encoderq_output.numpy()\n",
    "        cases.append(t) \n",
    "        \n",
    "        return cases\n",
    "\n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9762ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decoderlayer(target, create_look_ahead_mask):\n",
    "    def g():\n",
    "        num_heads=8\n",
    "        tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "        decoderLayerq = target(\n",
    "            embedding_dim=4, \n",
    "            num_heads=num_heads,\n",
    "            fully_connected_dim=32, \n",
    "            dropout_rate=0.1, \n",
    "            layernorm_eps=1e-6)\n",
    "\n",
    "        encoderq_output = tf.constant([[[-0.4,  0.4, -1.2,   1.5],\n",
    "                                       [ 0.4,   0.2, -1.6,   0.9],\n",
    "                                       [ 0.4,  -1.6,  0.1,   1.2]]])\n",
    "\n",
    "        q = np.array([[[1, 0, 1, 1], [1, 0, 1, 1], [1, 0, 1, 1]]]).astype(np.float32)\n",
    "\n",
    "        look_ahead_mask = create_look_ahead_mask(q.shape[1])\n",
    "\n",
    "        padding_mask = None\n",
    "        out, attn_w_b1, attn_w_b2 = decoderLayerq(q, encoderq_output, True, look_ahead_mask, padding_mask)\n",
    "        \n",
    "        shape1 = (q.shape[0], num_heads, q.shape[1], q.shape[1])\n",
    "        \n",
    "        cases = []\n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(attn_w_b1):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for attn_w_b1. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(attn_w_b1)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "\n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(attn_w_b2):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for attn_w_b2. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(attn_w_b1)\n",
    "            cases.append(t)\n",
    "            return cases\n",
    "        cases.append(t)\n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(out):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for out. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(attn_w_b1)\n",
    "            cases.append(t)\n",
    "            return cases\n",
    "        cases.append(t)\n",
    "    \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(attn_w_b1).numpy()) != shape1:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of attn_w_b1. Expected shape: {shape1}\"\n",
    "            t.want = shape1\n",
    "            t.got = tuple(tf.shape(attn_w_b1).numpy())\n",
    "        cases.append(t)  \n",
    "\n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(attn_w_b2).numpy()) != shape1:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of attn_w_b2. Expected shape: {shape1}\"\n",
    "            t.want = shape1\n",
    "            t.got = tuple(tf.shape(attn_w_b2).numpy())\n",
    "        cases.append(t)  \n",
    "        \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(out).numpy()) != q.shape:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of out. Expected shape: {q.shape}\"\n",
    "            t.want = q.shape\n",
    "            t.got = tuple(tf.shape(out).numpy())\n",
    "        cases.append(t)  \n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(attn_w_b1[0, 0, 1], [0.5, 0.5, 0.], atol=1e-2):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in 'attn_w_b1'. Check the call to self.mha1\"\n",
    "            t.want = [0.5, 0.5, 0.]\n",
    "            t.got = attn_w_b1[0, 0, 1]\n",
    "        cases.append(t)   \n",
    "    \n",
    "        t = test_case()\n",
    "        if not np.allclose(attn_w_b2[0, 0, 1], [0.34003818, 0.32569194, 0.33426988]):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in 'attn_w_b2'. Check the call to self.mha2\"\n",
    "            t.want = [0.34003818, 0.32569194, 0.33426988]\n",
    "            t.got = attn_w_b2[0, 0, 1]\n",
    "        cases.append(t)      \n",
    "    \n",
    "        t = test_case()\n",
    "        if not np.allclose(out[0, 0], [1.1810006, -1.5600019, 0.41289005, -0.03388882]):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in 'out'\"\n",
    "            t.want = [1.1810006, -1.5600019, 0.41289005, -0.03388882]\n",
    "            t.got = out[0, 0]\n",
    "        cases.append(t)  \n",
    "        \n",
    "        # Now let's try a example with padding mask\n",
    "        padding_mask = np.array([[[1, 1, 0]]])\n",
    "        out, attn_w_b1, attn_w_b2 = decoderLayerq(q, encoderq_output, True, look_ahead_mask, padding_mask)\n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(out[0, 0], [1.1297308, -1.6106694, 0.32352272, 0.15741566]):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in 'out' when we mask the last word. Are you passing the padding_mask to the inner functions?\"\n",
    "            t.want = [1.1297308, -1.6106694, 0.32352272, 0.15741566]\n",
    "            t.got = out[0, 0]\n",
    "        cases.append(t)  \n",
    "        \n",
    "        return cases\n",
    "\n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decoder(target, create_look_ahead_mask, create_padding_mask):\n",
    "    def g():\n",
    "        tf.keras.utils.set_random_seed(SEED)\n",
    "        \n",
    "        num_layers=7\n",
    "        embedding_dim=4 \n",
    "        num_heads=3\n",
    "        fully_connected_dim=8\n",
    "        target_vocab_size=33\n",
    "        maximum_position_encoding=6\n",
    "\n",
    "        x = np.array([[3, 2, 1], [2, 1, 0]])\n",
    "\n",
    "\n",
    "        encoderq_output = tf.constant([[[-0.2,  0.1, -1.3,  1.0],\n",
    "                                        [ 0.4,  0.6, -1.1,  0.7],\n",
    "                                        [ 0.1, -1.6,  0.3,  1.1]],\n",
    "                                       [[-0.7,  0.2, -1.1,  1.0],\n",
    "                                        [-0.2, -0.2, -1.0,  1.2],\n",
    "                                        [ 0.8, -1.1,  0.4,  1.3]]])\n",
    "\n",
    "        look_ahead_mask = create_look_ahead_mask(x.shape[1])\n",
    "\n",
    "        decoderk = target(num_layers,\n",
    "                        embedding_dim, \n",
    "                        num_heads, \n",
    "                        fully_connected_dim,\n",
    "                        target_vocab_size,\n",
    "                        maximum_position_encoding)\n",
    "        outd, att_weights = decoderk(x, encoderq_output, False, look_ahead_mask, None)\n",
    "        \n",
    "        cases = []\n",
    "        \n",
    "        t = test_case()\n",
    "        if not isinstance(att_weights, dict):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for attention_weights. Output must be a dictionary\"\n",
    "            t.want = type({1:2})\n",
    "            t.got = type(att_weights)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "\n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(outd):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for x. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(outd)\n",
    "            cases.append(t)\n",
    "            return cases\n",
    "        cases.append(t)\n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(tf.shape(outd), tf.shape(encoderq_output)):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of x. Expected shape: {tf.shape(encoderq_output)}\"\n",
    "            t.want = tf.shape(encoderq_output)\n",
    "            t.got = tf.shape(outd)\n",
    "        cases.append(t)  \n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(outd[1, 1], [1.6461557, -0.7657816, -0.04255769, -0.8378165]):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in x\"\n",
    "            t.want = [1.6461557, -0.7657816, -0.04255769, -0.8378165]\n",
    "            t.got = outd[1, 1]\n",
    "        cases.append(t)   \n",
    "\n",
    "        keys = list(att_weights.keys())\n",
    "\n",
    "        t = test_case()\n",
    "        if len(keys) != 2 * num_layers:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong length for attention weights. It must be 2 x num_layers = {2*num_layers}\"\n",
    "            t.want = 2 * num_layers\n",
    "            t.got = len(keys)\n",
    "        cases.append(t)    \n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(att_weights[keys[0]]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong type for att_weights[{keys[0]}]. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(att_weights[keys[0]])\n",
    "            cases.append(t)\n",
    "            return cases\n",
    "        cases.append(t)   \n",
    "    \n",
    "        shape1 = (x.shape[0], num_heads, x.shape[1], x.shape[1])\n",
    "        \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(att_weights[keys[1]]).numpy()) != shape1:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of attention_weights[{keys[1]}]. Expected shape: {shape1}\"\n",
    "            t.want = shape1\n",
    "            t.got = tf.shape(att_weights[keys[1]]).numpy()\n",
    "        cases.append(t)  \n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(att_weights[keys[0]][0, 0, 1], [0.51728565, 0.48271435, 0.]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong values in att_weights[{keys[0]}]\"\n",
    "            t.want = [0.51728565, 0.48271435, 0.]\n",
    "            t.got = att_weights[keys[0]][0, 0, 1]\n",
    "        cases.append(t)\n",
    "        \n",
    "        outd, att_weights = decoderk(x, encoderq_output, True, look_ahead_mask, None)\n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(outd[1, 1], [1.6286429, -0.7686589, 0.00983591, -0.86982]):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in outd when training=True\"\n",
    "            t.want = [1.6286429, -0.7686589, 0.00983591, -0.86982]\n",
    "            t.got = outd[1, 1]\n",
    "        cases.append(t)\n",
    "        \n",
    "        outd, att_weights = decoderk(x, encoderq_output, True, look_ahead_mask, create_padding_mask(x))\n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(outd[1, 1], [1.390952, 0.2794097, -0.2910638, -1.3792979]):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in outd when training=True and use padding mask\"\n",
    "            t.want = [1.390952, 0.2794097, -0.2910638, -1.3792979]\n",
    "            t.got = outd[1, 1]\n",
    "        cases.append(t)\n",
    "\n",
    "        return cases\n",
    "\n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd86b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transformer(target, create_look_ahead_mask, create_padding_mask):\n",
    "    def g():\n",
    "        tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "        num_layers = 6\n",
    "        embedding_dim = 4\n",
    "        num_heads = 4\n",
    "        fully_connected_dim = 8\n",
    "        input_vocab_size = 30\n",
    "        target_vocab_size = 35\n",
    "        max_positional_encoding_input = 5\n",
    "        max_positional_encoding_target = 6\n",
    "\n",
    "        transformer = target(num_layers, \n",
    "            embedding_dim, \n",
    "            num_heads, \n",
    "            fully_connected_dim, \n",
    "            input_vocab_size, \n",
    "            target_vocab_size, \n",
    "            max_positional_encoding_input,\n",
    "            max_positional_encoding_target)\n",
    "        \n",
    "        # 0 is the padding value\n",
    "        sentence_a = np.array([[2, 3, 4, 3, 0]])\n",
    "        sentence__b = np.array([[1, 2, 4, 0, 0]])\n",
    "\n",
    "        enc_padding_mask = create_padding_mask(sentence_a)\n",
    "        dec_padding_mask = create_padding_mask(sentence__b)\n",
    "\n",
    "        look_ahead_mask = create_look_ahead_mask(sentence_a.shape[1])\n",
    "\n",
    "        summary, weights = transformer(\n",
    "            sentence_a,\n",
    "            sentence__b,\n",
    "            True,  # Training\n",
    "            enc_padding_mask,\n",
    "            look_ahead_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        cases = []        \n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(summary):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for summary. Output must be a tensor\"\n",
    "            t.want = \"Tensor\"\n",
    "            t.got = type(summary)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "        \n",
    "        shape1 = (sentence_a.shape[0], max_positional_encoding_input, target_vocab_size)\n",
    "        \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(summary).numpy()) != shape1:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of summary. Expected shape: {shape1}\"\n",
    "            t.want = shape1\n",
    "            t.got = tf.shape(summary).numpy()\n",
    "        cases.append(t)\n",
    "\n",
    "        summary_example_1 = [0.04855702, 0.03407773, 0.01294427, 0.05483282, 0.03182802, 0.01409046, 0.02963346, 0.04003222]\n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(summary[0, 0, 0:8], summary_example_1):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in summary\"\n",
    "            t.want = summary_example_1\n",
    "            t.got = summary[0, 0, 0:8]\n",
    "        cases.append(t)           \n",
    "\n",
    "        t = test_case()\n",
    "        if not isinstance(weights, dict):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for attention weights. It must be a dictionary\"\n",
    "            t.want = type({1:2})\n",
    "            t.got = type(weights)\n",
    "            cases.append(t) \n",
    "            return cases\n",
    "        cases.append(t)        \n",
    "        \n",
    "        keys = list(weights.keys())        \n",
    "        t = test_case()\n",
    "        if len(keys) != 2 * num_layers:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong length for attention weights. It must be 2 x num_layers = {2*num_layers}\"\n",
    "            t.want = 2 * num_layers\n",
    "            t.got = len(keys)\n",
    "        cases.append(t)    \n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(weights[keys[0]]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong type for attention_weights[{keys[0]}]. Output must be a tensor\"\n",
    "            t.want = \"A tensor\"\n",
    "            t.got = type(weights[keys[0]])\n",
    "            cases.append(t)\n",
    "            return cases\n",
    "        cases.append(t)   \n",
    "\n",
    "        shape2 = (sentence_a.shape[0], num_heads, sentence_a.shape[1], sentence_a.shape[1])\n",
    "        \n",
    "        t = test_case()\n",
    "        if tuple(tf.shape(weights[keys[0]]).numpy()) != shape2:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong shape of attention_weights[{keys[0]}]. Expected shape: {shape2}\"\n",
    "            t.want = shape2\n",
    "            t.got = tf.shape(weights[keys[0]]).numpy()\n",
    "        cases.append(t)\n",
    "        \n",
    "        t = test_case()\n",
    "        if not np.allclose(weights[keys[0]][0, 0, 1], [0.481374, 0.51862603, 0.0, 0.0, 0.0]):\n",
    "            t.failed = True\n",
    "            t.msg = f\"Wrong values in weights[{keys[0]}]\"\n",
    "            t.want = [0.481374, 0.51862603, 0.0, 0.0, 0.0]\n",
    "            t.got = weights[keys[0]][0, 0, 1]\n",
    "        cases.append(t)           \n",
    "\n",
    "        tf.keras.utils.set_random_seed(SEED)\n",
    "        summary, weights = transformer(\n",
    "            sentence_a,\n",
    "            sentence__b,\n",
    "            False, # Training\n",
    "            enc_padding_mask,\n",
    "            look_ahead_mask,\n",
    "            dec_padding_mask)\n",
    "        \n",
    "        summary_example_2 = [0.05015587, 0.02734077, 0.01308834, 0.04876801, 0.03092919, 0.02046618, 0.02923589, 0.03272967]\n",
    "\n",
    "        t = test_case()\n",
    "        if not np.allclose(summary[0, 0, 0:8], summary_example_2):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong values in summary\"\n",
    "            t.want = summary_example_2\n",
    "            t.got = summary[0, 0, 0:8]\n",
    "        cases.append(t)                \n",
    "        \n",
    "        return cases\n",
    "\n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_next_word(target, model, encoder_input, output):\n",
    "    def g():\n",
    "        \n",
    "        next_word = target(model, encoder_input, output)\n",
    "\n",
    "        cases = []        \n",
    "        \n",
    "        t = test_case()\n",
    "        if not tf.is_tensor(next_word):\n",
    "            t.failed = True\n",
    "            t.msg = \"Wrong type for predicted_id Output must be a tensor\"\n",
    "            t.want = \"Tensor\"\n",
    "            t.got = type(next_word)\n",
    "            return [t]\n",
    "        cases.append(t)\n",
    "        \n",
    "        t = test_case()\n",
    "        if next_word.dtype != tf.int32:\n",
    "            t.failed = True\n",
    "            t.msg = f\"Returned tensor should contain tf.int32 type\"\n",
    "            t.want = tf.int32\n",
    "            t.got = next_word.dtype\n",
    "        cases.append(t)\n",
    "\n",
    "        return cases\n",
    "\n",
    "    cases = g()\n",
    "    print_feedback(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59a190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbc299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
